{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMy9dlpHLPqtOyHkuylrBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazaineam1/BigData2023_2/blob/main/Cuadernos/5_Vertexai_Workbench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Workbench de Vertex AI***\n",
        "\n",
        "## ***Universidad Central***\n",
        ">## **Facultad de Ingeniería y Ciencias Básicas.**\n",
        ">## ***Maestría en analítica de datos***\n",
        "![Imágen1](https://www.ucentral.edu.co/themes/ucentral/img/template/Universidad%20Central.png)\n",
        "\n",
        "\n",
        ">## ***Big Data.***\n",
        ">## ***Docente: Antonino Zainea Maya.***"
      ],
      "metadata": {
        "id": "uMFv9dG25Jzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Google Cloud Vertex AI Notebooks\n",
        "\n",
        "## Introducción\n",
        "\n",
        "Google Cloud Vertex AI Notebooks es un servicio que te permite crear y gestionar entornos de desarrollo basados en Jupyter Notebook en la nube de Google. Esto es útil para ejecutar código de datos, experimentos de aprendizaje automático, análisis de datos y más, todo dentro de un entorno colaborativo y escalable.\n",
        "\n",
        "En este tutorial, cubriremos tres conceptos clave:\n",
        "\n",
        "1. **Instancias**: Las instancias son las máquinas virtuales en la nube que alojarán tus Notebooks. Puedes configurar diferentes tipos de instancias con distintos recursos computacionales según tus necesidades.\n",
        "\n",
        "> Personalización Total: Las instancias te brindan control total sobre la configuración. Puedes seleccionar la imagen de la instancia, elegir la cantidad de CPU, memoria y almacenamiento, y configurar opciones avanzadas como el uso de GPU y la red.\n",
        "\n",
        ">Administración de Software: Eres responsable de instalar y gestionar las bibliotecas y software en la instancia. Esto permite una personalización completa pero también conlleva una mayor carga de administración.\n",
        "\n",
        ">Ideal para Usuarios Avanzados: Las instancias son ideales para usuarios avanzados que desean configurar un entorno de desarrollo específico y administrar sus propias bibliotecas y software.\n",
        "\n",
        ">Control de Recursos: Puedes configurar los recursos de la instancia según tus necesidades y ajustarlos en cualquier momento.\n",
        "\n",
        "2. **Notebooks administrados por el usuario**: Estos Notebooks se ejecutan en tu propia instancia, lo que te brinda un control completo sobre la configuración. Son adecuados para aquellos que desean personalizar su entorno y administrar su software y bibliotecas.\n",
        "\n",
        ">Entorno Propio: Los Notebooks administrados por el usuario se ejecutan en tu propia instancia, lo que significa que tienes control total sobre la configuración del entorno.\n",
        "\n",
        ">Personalización de Software: Eres responsable de instalar y administrar las bibliotecas y software en el entorno de JupyterLab. Esto te brinda flexibilidad para personalizar el entorno de desarrollo según tus necesidades.\n",
        "\n",
        ">Alta Personalización: Son ideales para usuarios que desean una personalización completa de su entorno de desarrollo y están dispuestos a administrar las configuraciones.\n",
        "\n",
        ">Mantén el Control: Tienes control total sobre las actualizaciones de software y las bibliotecas, lo que te permite mantener el entorno de desarrollo como desees.\n",
        "\n",
        "3. **Notebooks administrados**: Los Notebooks administrados son gestionados por Google Cloud. Son ideales para aquellos que desean evitar la administración de la infraestructura y centrarse en la codificación y el análisis de datos.\n",
        "\n",
        ">Gestionados por Google: Los Notebooks administrados son gestionados por Google Cloud. Google se encarga de la infraestructura, las actualizaciones de software y la seguridad.\n",
        "\n",
        ">Imágenes Preconfiguradas: Se ejecutan en entornos preconfigurados con imágenes proporcionadas por Google Cloud. Estas imágenes contienen bibliotecas comunes y están listas para su uso.\n",
        "\n",
        ">Sin Preocupaciones de Administración: Son ideales para usuarios que desean evitar la administración de la infraestructura y centrarse en la codificación y el análisis de datos.\n",
        "\n",
        "> Actualizaciones Automáticas: Google Cloud se encarga de mantener el entorno actualizado, lo que garantiza que siempre esté funcionando con las últimas actualizaciones de seguridad y software."
      ],
      "metadata": {
        "id": "02fXJ75EzrdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Paso 1: Acceder a Google Cloud Console\n",
        "\n",
        "Para comenzar, abre un navegador web y accede a [Google Cloud Console](https://console.cloud.google.com/).\n",
        "\n",
        "## Paso 2: Crear una instancia\n",
        "\n",
        "### Instancias\n",
        "\n",
        "1. En el menú de la izquierda, ve a \"Vertex AI\" y selecciona \"Notebooks\".\n",
        "\n",
        "2. Haz clic en \"Crear instancia\".\n",
        "\n",
        "3. Proporciona un nombre único para tu instancia y selecciona una ubicación geográfica. Esto determinará dónde se ejecutará tu instancia en la infraestructura de Google Cloud.\n",
        "\n",
        "4. Escoge una imagen de instancia. Puedes seleccionar una imagen predeterminada que incluye software y bibliotecas comunes o crear una imagen personalizada con tus configuraciones preferidas. Las imágenes predeterminadas incluyen versiones de Python y TensorFlow, entre otros.\n",
        "\n",
        "5. Elige el tipo de instancia y configura los recursos según tus necesidades. Puedes seleccionar desde instancias de CPU estándar hasta instancias con GPU para cargas de trabajo intensivas en cómputo. También puedes configurar la cantidad de memoria y el espacio de almacenamiento.\n",
        "\n",
        "6. Opcionalmente, puedes configurar opciones avanzadas, como GPU y la red. Esto te permite personalizar aún más tu instancia para cumplir con los requisitos de tu proyecto.\n",
        "\n",
        "7. Haz clic en \"Crear\" para crear la instancia. Google Cloud desplegará la máquina virtual según tus especificaciones.\n",
        "\n",
        "### Notebook administrado por el usuario\n",
        "\n",
        "8. En la página de inicio de Vertex AI Notebooks, selecciona la instancia recién creada. Verás una lista de instancias disponibles en tu proyecto.\n",
        "\n",
        "9. En la parte superior de la página de detalles de la instancia, haz clic en \"Abrir JupyterLab\" para acceder a tu entorno de desarrollo.\n",
        "\n",
        "10. Esto te llevará al entorno de JupyterLab en tu instancia, donde puedes crear, editar y ejecutar Notebooks. En este entorno, tienes control total sobre las bibliotecas y configuraciones de software, lo que te permite personalizar tu entorno según tus necesidades específicas.\n",
        "\n",
        "### Notebook administrado\n",
        "\n",
        "11. En la página de inicio de Vertex AI Notebooks, también puedes crear Notebooks administrados. Estos Notebooks se ejecutan en un entorno gestionado por Google Cloud, lo que significa que Google se encarga de la infraestructura y las actualizaciones de software.\n",
        "\n",
        "12. Haz clic en \"Crear notebook administrado\".\n",
        "\n",
        "13. Proporciona un nombre único para el notebook y selecciona una ubicación geográfica. Esto determinará dónde se ejecutará el notebook en la infraestructura de Google Cloud.\n",
        "\n",
        "14. Escoge una imagen de notebook. Google Cloud proporciona imágenes preconfiguradas con bibliotecas comunes, lo que facilita la configuración. Puedes seleccionar entre varias versiones de Python y otras opciones.\n",
        "\n",
        "15. Haz clic en \"Crear\" para crear el notebook administrado. Google Cloud desplegará el entorno de desarrollo y lo mantendrá actualizado automáticamente.\n",
        "\n",
        "## Paso 3: Usar tu Notebook\n",
        "\n",
        "Una vez que estés en tu entorno de JupyterLab, puedes crear, editar y ejecutar Notebooks de la misma manera tanto en los Notebooks administrados por el usuario como en los administrados. Aprovecha este espacio para desarrollar, realizar análisis de datos y ejecutar experimentos de aprendizaje automático.\n",
        "\n",
        "## Paso 4: Detener y Eliminar\n",
        "\n",
        "### Detener la instancia\n",
        "\n",
        "Si no estás usando tu instancia, puedes detenerla para ahorrar costos. Ve a la página de inicio de Vertex AI Notebooks, selecciona la instancia y haz clic en \"Detener\". Esto detendrá la máquina virtual y, por lo tanto, la facturación se reducirá al mínimo.\n",
        "\n",
        "### Eliminar la instancia o el notebook administrado\n",
        "\n",
        "Si ya no necesitas una instancia o un notebook administrado, puedes eliminarlos desde la página de inicio de Vertex AI Notebooks. Selecciónalos y haz clic en \"Eliminar\". Ten cuidado, ya que esto eliminará todos los datos asociados, incluidos los Notebooks y archivos.\n",
        "\n"
      ],
      "metadata": {
        "id": "XJs67yhE0jbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicia un notebook de Vertex AI Workbench\n",
        "\n",
        "Siga estos pasos para crear y lanzar un notebook de Vertex AI Workbench:\n",
        "\n",
        "1. En el Menú de navegación Ícono del menú de navegación, haga clic en Vertex AI > Workbench.\n",
        "\n",
        "2. En la página de Workbench, haga clic en Nuevo notebook.\n",
        "\n",
        "3. En el menú Customize instance, seleccione TensorFlow Enterprise y elija la versión más reciente de TensorFlow Enterprise 2.x (with LTS) > Without GPUs.\n",
        "\n",
        "4. Dele un nombre al notebook.\n",
        "4. Establezca la Región en <filled in at lab start> y la Zona en cualquiera que esté en la región designada.\n",
        "\n",
        "6. En las Propiedades del notebook, haga clic en el ícono de lápiz ícono de lápiz para editar las propiedades de la instancia.\n",
        "\n",
        "7. Desplácese hacia abajo hasta Configuración de la máquina y seleccione e2-standard-2 para Tipo de máquina.\n",
        "\n",
        "8. Deje los campos restantes con su configuración predeterminada y haga clic en Crear.\n",
        "\n",
        "9. Luego de unos minutos, la página de Workbench mostrará su instancia y aparecerá Open JupyterLab.\n",
        "\n",
        "10. Haga clic en Open JupyterLab para abrir JupyterLab en una pestaña nueva.\n",
        "\n",
        "\n",
        "Clona el repositorio de ejemplo en tu instancia de Workbench\n",
        "Para clonar el cuaderno training-data-analyst en su instrancia JupyterLab:\n",
        "\n",
        "En JupyterLab, haga clic en el icono Terminal para abrir una nueva terminal\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/GoogleCloudPlatform/training-data-analyst\n",
        "```\n",
        "Confirme que ha clonado el repositorio haciendo doble clic en el directorio training-data-analyst y asegúrese de que puede ver su contenido. Los archivos para todos los laboratorios basados ​​en notebook Jupyter a lo largo de este curso están disponibles en este directorio."
      ],
      "metadata": {
        "id": "9u5sQIHw4eHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Navega al notebook de ejemplo\n",
        "Navega a training-data-analyst/self-paced-labs/ai-platform-qwikstart y abre ai_platform_qwik_start.ipynb.\n",
        "\n",
        "Borra todas las celdas en el notebook (en la barra de herramientas del notebook, navega a Editar > Borrar todos los resultados) y, luego, ejecuta las celdas una por una."
      ],
      "metadata": {
        "id": "vsdD5ikG5CJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este tutorial te guía a través de la creación, entrenamiento y despliegue de un modelo de aprendizaje automático en Google Cloud AI Platform. El objetivo es desarrollar un modelo que prediga la categoría de ingresos de una persona (mayor o igual a $50,000 o menor a $50,000) basándose en datos demográficos. A continuación, se detallan los pasos:\n",
        "\n",
        "### Paso 1: Obtener tus datos de entrenamiento\n",
        "1. Descarga los archivos de datos `adult.data` y `adult.test` de un depósito público de Google Cloud Storage utilizando el comando `gsutil`. Estos archivos contienen los datos de entrenamiento y prueba. También establece variables de entorno para las rutas de estos archivos.\n",
        "\n",
        "```bash\n",
        "mkdir data\n",
        "gsutil -m cp gs://cloud-samples-data/ml-engine/census/data/* data/\n",
        "export TRAIN_DATA=$(pwd)/data/adult.data.csv\n",
        "export EVAL_DATA=$(pwd)/data/adult.test.csv\n",
        "```\n",
        "\n",
        "2. Puedes verificar el aspecto de los datos usando el comando `head`:\n",
        "\n",
        "```bash\n",
        "head data/adult.data.csv\n",
        "```\n",
        "\n",
        "### Paso 2: Ejecutar un trabajo de entrenamiento local\n",
        "1. Crea archivos para contener tu programa de entrenamiento en Python. Estos archivos son `util.py`, `model.py` y `task.py`. `util.py` contiene funciones para la descarga y limpieza de datos, `model.py` define la arquitectura del modelo, y `task.py` es el script principal de entrenamiento.\n",
        "\n",
        "2. Ejecuta los siguientes comandos para crear estos archivos:\n",
        "\n",
        "```bash\n",
        "mkdir -p trainer\n",
        "touch trainer/__init__.py\n",
        "```\n",
        "\n",
        "Luego, crea los archivos `util.py`, `model.py` y `task.py` con el contenido proporcionado en el tutorial.\n",
        "\n",
        "3. Entrena tu modelo localmente con el siguiente comando:\n",
        "\n",
        "```bash\n",
        "MODEL_DIR=output\n",
        "gcloud ai-platform local train \\\n",
        "    --module-name trainer.task \\\n",
        "    --package-path trainer/ \\\n",
        "    --job-dir $MODEL_DIR \\\n",
        "    -- \\\n",
        "    --train-files $TRAIN_DATA \\\n",
        "    --eval-files $EVAL_DATA \\\n",
        "    --train-steps 1000 \\\n",
        "    --eval-steps 100\n",
        "```\n",
        "\n",
        "Este comando entrena el modelo localmente utilizando los datos de entrenamiento y evaluación.\n",
        "\n",
        "### Paso 3: Preparar la entrada para la predicción\n",
        "1. Para realizar predicciones, primero debes preprocesar los datos de entrada de la misma manera que se preprocesaron los datos de entrenamiento. En este caso, usa una muestra de datos de evaluación para hacer predicciones.\n",
        "\n",
        "```python\n",
        "from trainer import util\n",
        "\n",
        "_, _, eval_x, eval_y = util.load_data()\n",
        "\n",
        "prediction_input = eval_x.sample(5)\n",
        "prediction_targets = eval_y[prediction_input.index]\n",
        "```\n",
        "\n",
        "2. Exporta los datos de entrada de predicción a un archivo JSON llamado `test.json`:\n",
        "\n",
        "```python\n",
        "import json\n",
        "\n",
        "with open('test.json', 'w') as json_file:\n",
        "  for row in prediction_input.values.tolist():\n",
        "    json.dump(row, json_file)\n",
        "    json_file.write('\\n')\n",
        "```\n",
        "\n",
        "### Paso 4: Utilizar tu modelo entrenado para la predicción\n",
        "1. Ejecuta el siguiente comando para hacer predicciones en el archivo JSON de prueba:\n",
        "\n",
        "```bash\n",
        "gcloud ai-platform local predict \\\n",
        "    --model-dir output/keras_export/ \\\n",
        "    --json-instances ./test.json\n",
        "```\n",
        "\n",
        "Este comando utiliza el modelo entrenado para realizar predicciones en los datos de prueba y muestra los resultados.\n",
        "\n",
        "### Paso 5: Ejecutar tu trabajo de entrenamiento en la nube\n",
        "1. Antes de ejecutar tu trabajo de entrenamiento en la nube, configura un depósito de Google Cloud Storage (GCS) para almacenar tus datos y resultados de entrenamiento.\n",
        "\n",
        "2. Utiliza el comando `gsutil` para crear el depósito:\n",
        "\n",
        "```bash\n",
        "export PROJECT=<Tu proyecto de GCP>\n",
        "export BUCKET_NAME=${PROJECT}-aiplatform\n",
        "export REGION=\"us-central1\"\n",
        "```\n",
        "\n",
        "3. Copia los datos de entrenamiento, evaluación y el archivo JSON de prueba al depósito de GCS:\n",
        "\n",
        "```bash\n",
        "gsutil mb -l ${REGION} gs://${BUCKET_NAME}\n",
        "gsutil cp -r data gs://$BUCKET_NAME/data\n",
        "gsutil cp test.json gs://$BUCKET_NAME/data/test.json\n",
        "```\n",
        "\n",
        "4. Establece variables de entorno para las rutas de los datos en GCS:\n",
        "\n",
        "```bash\n",
        "export TRAIN_DATA=gs://$BUCKET_NAME/data/adult.data.csv\n",
        "export EVAL_DATA=gs://$BUCKET_NAME/data/adult.test.csv\n",
        "export TEST_JSON=gs://$BUCKET_NAME/data/test.json\n",
        "```\n",
        "\n",
        "5. Ejecuta tu trabajo de entrenamiento en la nube utilizando el siguiente comando:\n",
        "\n",
        "```bash\n",
        "OUTPUT_PATH=gs://$BUCKET_NAME/$JOB_ID\n",
        "MODEL_BINARIES=$OUTPUT_PATH/keras_export/\n",
        "gcloud ai-platform jobs submit training $JOB_ID \\\n",
        "    --stream-logs \\\n",
        "    --runtime-version $TFVERSION \\\n",
        "    --python-version $PYTHONVERSION \\\n",
        "    --package-path trainer/ \\\n",
        "    --module-name trainer.task \\\n",
        "    --job-dir $OUTPUT_PATH \\\n",
        "    --region $REGION \\\n",
        "    -- \\\n",
        "    --train-files $TRAIN_DATA \\\n",
        "    --eval-files $EVAL_DATA \\\n",
        "   \n",
        "\n",
        " --train-steps 1000 \\\n",
        "    --eval-steps 100\n",
        "```\n",
        "\n",
        "Este comando envía un trabajo de entrenamiento en la nube que utiliza los datos almacenados en GCS.\n",
        "\n",
        "### Paso 6: Desplegar tu modelo para realizar predicciones en línea\n",
        "1. Crea un modelo de AI Platform utilizando el siguiente comando:\n",
        "\n",
        "```bash\n",
        "export MODEL_NAME=\"census\"\n",
        "gcloud ai-platform models create $MODEL_NAME --regions=$REGION\n",
        "```\n",
        "\n",
        "2. Establece una variable de entorno para la ruta de los modelos binarios exportados:\n",
        "\n",
        "```bash\n",
        "export MODEL_BINARIES=$OUTPUT_PATH/keras_export/\n",
        "```\n",
        "\n",
        "3. Crea una versión `v1` de tu modelo con el siguiente comando:\n",
        "\n",
        "```bash\n",
        "gcloud ai-platform versions create v1 \\\n",
        "    --model $MODEL_NAME \\\n",
        "    --origin $MODEL_BINARIES \\\n",
        "    --runtime-version $TFVERSION \\\n",
        "    --python-version $PYTHONVERSION \\\n",
        "    --region=global\n",
        "```\n",
        "\n",
        "4. Espera a que se complete la implementación del modelo. Puedes verificar el estado utilizando el siguiente comando:\n",
        "\n",
        "```bash\n",
        "gcloud ai-platform models list --region=global\n",
        "```\n",
        "\n",
        "### Paso 7: Enviar una solicitud de predicción en línea\n",
        "1. Envía una solicitud de predicción en línea utilizando el siguiente comando:\n",
        "\n",
        "```bash\n",
        "gcloud ai-platform predict \\\n",
        "    --model $MODEL_NAME \\\n",
        "    --version v1 \\\n",
        "    --json-instances ./test.json \\\n",
        "    --region global\n",
        "```\n",
        "\n",
        "Este comando utiliza el modelo desplegado para realizar predicciones en los datos de prueba y muestra los resultados.\n",
        "\n",
        "¡Listo! Has creado, entrenado y desplegado un modelo de aprendizaje automático en Google Cloud AI Platform y has realizado predicciones en línea con él."
      ],
      "metadata": {
        "id": "imiuv_6s12Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAdtvymc0jBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Da_AELQ7zulx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}